{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize \n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "df = df[:150000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(ques):\n",
    "    ques = str(ques)\n",
    "    ques = [str(word) for word in ques]\n",
    "    ques = \"\".join([word.lower() for word in ques if word not in string.punctuation])\n",
    "    ques = word_tokenize(ques)\n",
    "    ques = [ps.stem(word) for word in ques]\n",
    "    ques = [str(word) for word in ques]\n",
    "    ques = \" \".join(ques)\n",
    "    return ques\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''X_q1 = []\n",
    "X_q2 = []\n",
    "q1 = list(df['question1'])\n",
    "q2 = list(df['question2'])\n",
    "for ques in q1:\n",
    "    X_q1.append(preprocess_text(ques))\n",
    "for ques in q2:\n",
    "    X_q2.append(preprocess_text(ques))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for ind,row in df.iterrows():\n",
    "    X.append(preprocess_text(str(row['question1']) + \" \" + str(row['question2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''X = pd.DataFrame()\n",
    "X['question1'] = X_q1\n",
    "X['question2'] = X_q2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df['is_duplicate'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(list(X_train['question1']))\n",
    "X_train_q1 = tokenizer.texts_to_sequences(list(X_train['question1']))\n",
    "X_test_q1 = tokenizer.texts_to_sequences(list(X_test['question1']))\n",
    "\n",
    "tokenizer.fit_on_texts(list(X_train['question2']))\n",
    "X_train_q2 = tokenizer.texts_to_sequences(list(X_train['question2']))\n",
    "X_test_q2 = tokenizer.texts_to_sequences(list(X_test['question2']))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(list(X_train))\n",
    "X_test = tokenizer.texts_to_sequences(list(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train_q1 = pad_sequences(X_train_q1, padding='post', maxlen=maxlen)\n",
    "X_test_q1 = pad_sequences(X_test_q1, padding='post', maxlen=maxlen)\n",
    "\n",
    "X_train_q2 = pad_sequences(X_train_q2, padding='post', maxlen=maxlen)\n",
    "X_test_q2 = pad_sequences(X_test_q2, padding='post', maxlen=maxlen)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "f = open(r\"./glove.6B.100d.txt\", encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],dtype=np.float32)\n",
    "    embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings[word]\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45265"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          4526500   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 10001     \n",
      "=================================================================\n",
      "Total params: 4,536,501\n",
      "Trainable params: 10,001\n",
      "Non-trainable params: 4,526,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(X_train_q1)):\n",
    "    arr = []\n",
    "    arr.extend(X_train_q1[i])\n",
    "    arr.extend(X_train_q2[i])\n",
    "    X_train.append(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(len(X_test_q1)):\n",
    "    arr = []\n",
    "    arr.extend(X_test_q1[i])\n",
    "    arr.extend(X_test_q2[i])\n",
    "    X_test.append(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,dtype=np.float32)\n",
    "X_test = np.array(X_test,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.6116 - acc: 0.6636 - val_loss: 0.6142 - val_acc: 0.6717\n",
      "Epoch 2/6\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.5900 - acc: 0.6839 - val_loss: 0.6031 - val_acc: 0.6772\n",
      "Epoch 3/6\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5835 - acc: 0.6867 - val_loss: 0.6026 - val_acc: 0.6801\n",
      "Epoch 4/6\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.5807 - acc: 0.6895 - val_loss: 0.6099 - val_acc: 0.6686\n",
      "Epoch 5/6\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5792 - acc: 0.6896 - val_loss: 0.6109 - val_acc: 0.6699\n",
      "Epoch 6/6\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.5773 - acc: 0.6923 - val_loss: 0.6249 - val_acc: 0.6520\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 0.6223 - acc: 0.6545\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6222784519195557\n",
      "Test Accuracy: 0.6545000076293945\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          4526500   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 96, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,590,757\n",
      "Trainable params: 64,257\n",
      "Non-trainable params: 4,526,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "750/750 [==============================] - 46s 61ms/step - loss: 0.5644 - acc: 0.7068 - val_loss: 0.5430 - val_acc: 0.7249\n",
      "Epoch 2/6\n",
      "750/750 [==============================] - 43s 57ms/step - loss: 0.5001 - acc: 0.7539 - val_loss: 0.5083 - val_acc: 0.7488\n",
      "Epoch 3/6\n",
      "750/750 [==============================] - 46s 61ms/step - loss: 0.4611 - acc: 0.7791 - val_loss: 0.4946 - val_acc: 0.7567\n",
      "Epoch 4/6\n",
      "750/750 [==============================] - 44s 59ms/step - loss: 0.4268 - acc: 0.7981 - val_loss: 0.4915 - val_acc: 0.7614\n",
      "Epoch 5/6\n",
      "750/750 [==============================] - 44s 58ms/step - loss: 0.3965 - acc: 0.8171 - val_loss: 0.4959 - val_acc: 0.7582\n",
      "Epoch 6/6\n",
      "750/750 [==============================] - 42s 56ms/step - loss: 0.3668 - acc: 0.8347 - val_loss: 0.5221 - val_acc: 0.7558\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 0.5332 - acc: 0.7496\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.5331975817680359\n",
      "Test Accuracy: 0.7495666742324829\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 100)          4526500   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,643,877\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 4,526,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "750/750 [==============================] - 136s 182ms/step - loss: 0.6357 - acc: 0.6399 - val_loss: 0.6010 - val_acc: 0.6742\n",
      "Epoch 2/6\n",
      "750/750 [==============================] - 145s 194ms/step - loss: 0.5901 - acc: 0.6858 - val_loss: 0.5738 - val_acc: 0.7036\n",
      "Epoch 3/6\n",
      "750/750 [==============================] - 137s 183ms/step - loss: 0.5664 - acc: 0.7092 - val_loss: 0.5579 - val_acc: 0.7166\n",
      "Epoch 4/6\n",
      "750/750 [==============================] - 131s 175ms/step - loss: 0.5460 - acc: 0.7241 - val_loss: 0.5508 - val_acc: 0.7222\n",
      "Epoch 5/6\n",
      "750/750 [==============================] - 130s 173ms/step - loss: 0.5284 - acc: 0.7367 - val_loss: 0.5353 - val_acc: 0.7316\n",
      "Epoch 6/6\n",
      "750/750 [==============================] - 552s 735ms/step - loss: 0.5115 - acc: 0.7475 - val_loss: 0.5274 - val_acc: 0.7336\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.5255 - acc: 0.7335\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.525536298751831\n",
      "Test Accuracy: 0.7334666848182678\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
